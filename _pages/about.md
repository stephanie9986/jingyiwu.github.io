---
permalink: /
title: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a fifth-year Ph.D. candidate in Linguistics at Zhejiang University and a Visiting Scholar in Communication at UCLA. I'm very fortunate to be advised by [Professor Junying Liang](https://person.zju.edu.cn/en/jyleung#0) and [Professor Tao Gao](https://comm.ucla.edu/person/tao-gao/). My research spans a wide range of topics, including online popularity prediction, computational modeling of communication, and visual language. By combining methods from linguistics, communication, and cognitive science, I aim to better understand how people create, interpret, and respond to language in both digital and real-world contexts.

Research Interests
======

Online Popularity Prediction
------
What factors shape audience choices and determine the popularity of online talks? My Ph.D. dissertation addresses this question by examining TED Talks through a multi-modal analytic framework. The project analyzes topic clusters, narrative structures, sentiment trajectories, and visual design features such as video covers to uncover how linguistic, emotional, and visual variables interact to influence audience engagement.

Computational Modeling of Cooperative Communication
------
How do people communicate and coordinate under ambiguity? What cognitive and computational mechanisms allow us to signal meaning, resolve uncertainty, and align perspectives for joint action? Research in this area develops formal frameworks that integrate pragmatics, Theory of Mind, and shared agency, explaining how cooperation and joint planning shape communication in both linguistic and non-linguistic contexts. More broadly, this dimension explores how computational approaches can capture the efficiency and flexibility of human communication.

Grounding Verbs in Intuitive Physics
------
How do humans perceive and categorize actions in the visual world? What physical and geometric primitives—such as causation, force dynamics, and state change—underlie verb meanings and guide the rapid generalization of novel events? How do linguistic theories of verb semantics connect with perceptual systems to bridge language and visual cognition? How can computational models be built to capture these intuitions and to differentiate fine-grained actions, advancing both embodied theories of language and machine understanding of events?
